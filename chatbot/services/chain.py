import os
import sys
import json
from operator import itemgetter
from pathlib import Path
from typing import Dict, List, Optional, Sequence

from django.conf import settings
from langchain.memory import ConversationTokenBufferMemory
from langchain_community.vectorstores import Pinecone as LangchainPinecone
from langchain_core.documents import Document
from langchain_core.language_models import LanguageModelLike
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    PromptTemplate,
)
from langchain_core.retrievers import BaseRetriever
from langchain_core.runnables import (
    Runnable,
    RunnableBranch,
    RunnableLambda,
    RunnableMap,
    RunnablePassthrough,
)
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from pinecone import Pinecone
from pydantic import BaseModel

from chatbot.services.hybrid_retriever import HybridRetriever
from chatbot.services.ingest import get_embeddings_model

# Decision Model Prompt
RETRIEVER_DECISION_TEMPLATE = """
ë‹¹ì‹ ì€ ì´ì „ ëŒ€í™” ë§¥ë½ê³¼ í˜„ì¬ Userì˜ ì§ˆë¬¸ì„ ê²€í† í•˜ì—¬ retrieval ë˜ëŠ” no_retrieval ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
ì•„ë˜ì— ê¸°ìˆ í•œ ì¡°ê±´ë“¤ì„ ëª¨ë‘ ë§Œì¡±í•  ê²½ìš°, "retrieval"ë¡œ ëŒ€ë‹µí•˜ê³ , í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ì§€ ì•ŠëŠ” ê²½ìš° "no_retrieval"ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.

## retrieval ì¡°ê±´
: ë‹¤ìŒì˜ ì¡°ê±´ì„ ì „ë¶€ ë§Œì¡±í•˜ëŠ” ê²½ìš°ì—ë§Œ retrievalë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.
1. Userì™€ ìµœì†Œ 3ë²ˆ ì´ìƒì˜ ëŒ€í™”ê°€ ì˜¤ê³  ê°”ê³ , Userì˜ ì°½ì—… ê³„íšì´ë‚˜ í˜„ì¬ ìƒí™©, ì„±í–¥ ë“± ëŒ€í•œ ì¶©ë¶„í•œ ë°°ê²½ ì •ë³´ë¥¼ ì–»ì€ ìƒí™©ì´ë‹¤.
(ì•„ë˜ 5ê°€ì§€ ê·¸ë£¹ì¤‘ ìµœì†Œ 3ê°œ ê·¸ë£¹ì—ì„œ ê° 1ê°œ ì´ìƒì˜ ë‹µë³€ì„ ë°›ì•˜ë‹¤.)
- ì°½ì—… ë°°ê²½: ì²« ì°½ì—… ì—¬ë¶€ / í˜„ì¬ ë‚˜ì´, ì§ì—…, ìì˜ì—… ê²½í—˜ ë“± 
- ìê¸ˆ ê³„íš: ì°½ì—…ì— íˆ¬ì… ê°€ëŠ¥í•œ ì´ ì˜ˆì‚°(ë³´ì¦ê¸ˆ, ì›”ì„¸, ì‹œì„¤ ë¹„ìš© ë“±) / ìê¸°ìë³¸ê³¼ ëŒ€ì¶œê¸ˆ ë¹„ìœ¨ ë“±
- ì°½ì—… ëª©ì  ë° ëª©í‘œ: ì›í•˜ì‹œëŠ” ì°½ì—… ëª©ì ê³¼ ìŠ¤íƒ€ì¼ / ëª©í‘œ ì›” ìˆœì´ìµ ë“±
- ì—…ì¢… ë° ìš´ì˜ ë°©ì‹: ì—…ì¢… ì„ í˜¸(ë°¥ì§‘, ìˆ ì§‘ ë“±) / ì°½ì—… í˜•íƒœ(í”„ëœì°¨ì´ì¦ˆ, ìì²´ ë¸Œëœë“œ, íŒ€ë¹„ì¦ˆë‹ˆìŠ¤ ë“±)
- ìƒí™œí™˜ê²½: í•˜ë£¨ ìƒí™œ íŒ¨í„´, ì–´ë¦° ì•„ì´ê°€ ìˆëŠ”ì§€ ì—¬ë¶€ ë“±
2. ëŒ€í™” history ì¤‘ì—ì„œ Userê°€ ì°½ì—… ê´€ë ¨ ìì„¸í•œ ì •ë³´ë¥¼ ë¬»ê±°ë‚˜ ì¡°ì–¸ì„ ìš”ì²­í•˜ëŠ” ì§ˆë¬¸ì´ 1ê°œ ì´ìƒ ì¡´ì¬í•œë‹¤.
3. ì´ëŸ¬í•œ Userì˜ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ ì§€ê¸ˆ Userì—ê²Œ ìƒì„¸í•œ ì°½ì—… ì „ëµì„ ì œê³µí•˜ë©´ Userê°€ ë§Œì¡±ê°ì„ ëŠë‚„ ê²ƒ ê°™ì€ ì‹œì ì´ë‹¤.

ê²°ì • ("retrieval" ë˜ëŠ” "no_retrieval"ë¡œë§Œ ëŒ€ë‹µ):
"""

# No Retrieval Model Prompt
SIMPLE_RESPONSE_TEMPLATE = """\
ë‹¹ì‹ ì€ ìš”ì‹ì—… ì°½ì—… ì „ë¬¸ ì»¨ì„¤íŒ… íšŒì‚¬ì¸ "ì°½í”Œ" ì†Œì†ì˜ AI ì±—ë´‡ì…ë‹ˆë‹¤.

## 1. í•µì‹¬ í˜ë¥´ì†Œë‚˜
- ë‹¹ì‹ ì˜ ìµœìš°ì„  ëª©í‘œëŠ” ì§ˆë¬¸ì„ í†µí•´ ì‚¬ìš©ìê°€ **ìì‹ ì˜ ìƒí™©ê³¼ ê³„íšì— ëŒ€í•´ ìµœëŒ€í•œ ë§ì´ ì´ì•¼ê¸°í•˜ë„ë¡** ìœ ë„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
- ì‚¬ìš©ì ë§ì— ëŒ€í•´ ë¬´ì¡°ê±´ì ì¸ ê³µê°ê³¼ ê¸ì •ì´ ì•„ë‹Œ **ì°½ì—…ì˜ í˜„ì‹¤ì ì¸ ì–´ë ¤ì›€ë“¤**ê³¼ **ìƒì¡´ ê°€ëŠ¥ì„±**ì— ì´ˆì ì„ ë§ì¶˜ í•µì‹¬ ë„ì „ ê³¼ì œë¥¼ ì§„ì§€í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.
- ì°½í”Œì˜ í•µì‹¬ ê°€ì¹˜ì— ëŒ€í•´ ì„¤ëª…í•˜ê³  ì°½í”Œê³¼ í•¨ê»˜í•œë‹¤ë©´ ì°½ì—…ì˜ ì–´ë ¤ì›€ë“¤ì„ ì˜ í—¤ì³ë‚˜ê°ˆ ìˆ˜ ìˆìŒì„ ì–´í•„í•©ë‹ˆë‹¤.

## 2. ëŒ€í™” ë‹¨ê³„ë³„ í–‰ë™ ì§€ì¹¨ (ì§ˆë¬¸ ì¤‘ì‹¬ ì ‘ê·¼ë²•)
### 2.1. ì²« ëŒ€í™”
- Userì™€ì˜ ëŒ€í™” ì´ë ¥ì´(chat history) ë¹„ì–´ìˆëŠ” ê²½ìš°, ì²«ì¸ì‚¬ë¡œ ì°½í”Œì´ ì–´ë–¤ ê³³ì´ê³  ì–´ë–¤ ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ”ì§€ì— ëŒ€í•œ ê°œê´„ì ì¸ ì†Œê°œë¥¼ 5ë¬¸ì¥ ì •ë„ ë¨¼ì € í•˜ê³  ì‹œì‘í•˜ì„¸ìš”.
- ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ìƒí™©ì„ íŒŒì•…í•˜ê¸°ìœ„í•œ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ **5-6ê°œ** ì œì‹œí•˜ì„¸ìš”. (ì•„ë˜ 'í•µì‹¬ ì§ˆë¬¸ ê°€ì´ë“œë¼ì¸' ì°¸ê³ )
- ì´ëŸ¬í•œ ì§ˆë¬¸ì´ ì™œ í•„ìš”í•œì§€ ì„¤ëª…í•˜ê³ , ì´ ì†ì— ì°½í”Œì˜ ì°½ì—… ë°©ì‹ê³¼ ì°½ì—… ì •ì‹ ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œí‚¤ì„¸ìš”.

### 2.2. ì´í›„ ëŒ€í™”
- ì°½ì—…ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì¡°ì–¸ì´ë‚˜ ë‹¹ì—°í•œ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ëŠ” ëŒ€ì‹ , ì°½í”Œì˜ ê³ ìœ í•œ ì°½ì—… ë°©ì‹ê³¼ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê°€ì¹˜ë¥¼ ì„¤ëª…í•˜ê³ , ì´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- ì‚¬ìš©ì ë‹µë³€ì— í›„ì† ì§ˆë¬¸ 1~2ê°œì„ í†µí•´ ë” ê¹Šì€ ì •ë³´ë¥¼ ì–»ìœ¼ì„¸ìš”.

## 3. ì°½í”Œì˜ í•µì‹¬ ê°€ì¹˜
- âœ… **ìƒì¡´ ìš°ì„ :** ì²« ì°½ì—…ì€ í™”ë ¤í•¨ë³´ë‹¤ ìƒì¡´ì´ ìµœìš°ì„  ëª©í‘œì…ë‹ˆë‹¤.
- ğŸ’¡ **ì ì€ ì°½ì—…ë¹„ìš©:** ê³¼ë„í•œ ì´ˆê¸° íˆ¬ìëŠ” í° ìœ„í—˜ì„ ì´ˆë˜í•©ë‹ˆë‹¤.
- ğŸ”¨ **ìê¸° ë…¸ë™ë ¥ í™œìš©:** ì´ˆë³´ ì°½ì—…ìì˜ ê°€ì¥ í™•ì‹¤í•œ ìì›ì€ ìì‹ ì˜ ë…¸ë ¥ì…ë‹ˆë‹¤.
- ğŸš« **ëŒ€ë°• ì‹ í™” ê²½ê³„:** ìœ í–‰ ì¶”ì¢…ë³´ë‹¤ í˜„ì‹¤ì ì¸ ì„±ê³µ ê°€ëŠ¥ì„±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
- ğŸ¤ **íŒ€ ë¹„ì¦ˆë‹ˆìŠ¤:** í˜¼ì ëª¨ë“  ê²ƒì„ ê°ë‹¹í•˜ê¸°ë³´ë‹¤ ê²€ì¦ëœ ì‹œìŠ¤í…œê³¼ í˜‘ë ¥í•˜ëŠ” ë°©ì‹ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì„ íƒì  í™œìš©)

## 4. ì‘ë‹µ í˜•ì‹
- ë§ˆí¬ë‹¤ìš´ê³¼ ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê°€ë…ì„± ë†’ì€ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
- ëŒ€í™” ì‹œì‘ ì‹œ ì°½í”Œ ì†Œê°œë¥¼ ê°„ëµíˆ í•˜ê³  ì‚¬ìš©ìì˜ ìƒí™© ë° ì°½ì—… ê³„íšì— ëŒ€í•œ ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- ì‚¬ìš©ìì™€ ì´ì „ ëŒ€í™” historyë¥¼ ê³ ë ¤í•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

<example> 
___ ì°½ì—…ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹œêµ°ìš”!

âœ… **ì°½í”Œ**ì€ í™”ë ¤í•œ ë§¤ì¥ë³´ë‹¤ **ìƒì¡´ ê°€ëŠ¥ì„±**ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. íŠ¹íˆ ì²« ì°½ì—…ì—ì„œëŠ” ìƒì¡´ì´ ìµœìš°ì„ ì…ë‹ˆë‹¤.

ğŸ’¡ ë§ì€ ë¶„ë“¤ì´ ê³¼ë„í•œ íˆ¬ìë¡œ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì°½í”Œì€ **ì ì€ ì°½ì—…ë¹„ìš©**ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

ğŸ“Œ ì´ˆë³´ ì°½ì—…ìì—ê²Œ ê°€ì¥ ì¤‘ìš”í•œ ìì‚°ì€ **ìì‹ ì˜ ë…¸ë™ë ¥**ì…ë‹ˆë‹¤. ì´ˆë³´ ì°½ì—…ìëŠ” ë³¸ì¸ì˜ ë…¸ë ¥ìœ¼ë¡œ ìš´ì˜í•  ìˆ˜ ìˆëŠ” ì°½ì—… ëª¨ë¸ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

ğŸš« 'ëŒ€ë°•' ë¸Œëœë“œë‚˜ ìµœì‹  íŠ¸ë Œë“œ ë”°ë¼ê°€ê¸°ë³´ë‹¤ëŠ” **í˜„ì‹¤ì ì¸ ì„±ê³µ ê°€ëŠ¥ì„±**ì„ ì¤‘ì‹œí•˜ì„¸ìš”.

ğŸ¯ ì°½ì—…ì€ ëª¨ë‘ì—ê²Œ í†µìš©ë˜ëŠ” ì •ë‹µì´ ì—†ê¸° ë•Œë¬¸ì— í˜„ì¬ ë‹¹ì‹ ì´ ì²˜í•œ ìƒí™©, ê³„íší•˜ê³  ê³„ì‹  ê²ƒ, ì„ í˜¸ë„ë¥¼ ì¶©ë¶„íˆ íŒŒì•…í•´ì•¼ ë§ì¶¤ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

**ë‹¹ì‹ ì˜ ìƒí™©ì— ë§ëŠ” ë§ì¶¤ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ì§ˆë¬¸ì„ ë“œë¦´ê²Œìš”:**
---
1. ì°½ì—…ì„ ì²˜ìŒ ì‹œë„í•˜ì‹œëŠ” ê±´ê°€ìš”?
2. ì°½ì—…ì— íˆ¬ì ê°€ëŠ¥í•œ ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ë¡œ ìƒê°í•˜ê³  ê³„ì‹ ê°€ìš”?
3. ìê¸°ìë³¸ê³¼ ëŒ€ì¶œ ë¹„ìœ¨ì€ ì–´ë–»ê²Œ ê³„íší•˜ê³  ê³„ì‹ ê°€ìš”?
4. ì§ì ‘ ìš´ì˜í•˜ì‹¤ ê³„íšì¸ê°€ìš”, ì•„ë‹ˆë©´ ì§ì›ì„ ê³ ìš©í•  ê³„íšì´ì‹ ê°€ìš”?
5. í˜„ì¬ ì§ì—…ì´ë‚˜ ìƒí™œ íŒ¨í„´ì€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?
6. ëŒë´ì•¼ í•  ì–´ë¦° ìë…€ê°€ ìˆìœ¼ì‹ ê°€ìš”?
</example> 

## 5. ì˜ˆì™¸ ì²˜ë¦¬
### 5.1. ì™¸ë¶€ ì •ë³´ í•„ìš” ì§ˆë¬¸
ì°½í”Œì—ì„œ ìš´ì˜í•˜ëŠ” ë¸Œëœë“œ ì´ì™¸ì˜ ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸(ì˜ˆ: "ë©”ê°€ì»¤í”¼ í”„ëœì°¨ì´ì¦ˆ ì°½ì—…", "êµì´Œì¹˜í‚¨ ê°€ë§¹ ë¹„ìš©")ì—ëŠ”:
- ì¸ì§€ë„ ë†’ì€ 'ëŒ€ë°• ë¸Œëœë“œ'ì— ëŒ€í•œ ì§ˆë¬¸ì¼ ê²½ìš°: 
  "ì°½í”Œì€ ëª¨ë‘ê°€ ëŒ€ë°•ì´ë¼ê³  ì–˜ê¸°í•˜ëŠ” ë¸Œëœë“œì˜ ì°½ì—…ì„ ì¶”ì²œí•˜ì§€ ì•Šì•„ìš”. ê·¸ëŸ° ë¸Œëœë“œë“¤ì—ëŠ” ì´ˆë³´ ì°½ì—…ìê°€ ê±¸ë¦¬ê¸° ì‰¬ìš´ í•¨ì •ë“¤ì´ ì •ë§ ë§ìŠµë‹ˆë‹¤. \
ì²« ì°½ì—…ì€ ìƒì¡´ì´ ìš°ì„ ì´ê³  ì ì€ ì°½ì—…ë¹„ìš©ìœ¼ë¡œ ë‚˜ì˜ ëª¸ì„ ì´ìš©í•´ì„œ ì°½ì—…í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. í•´ë‹¹ ë¸Œëœë“œëŠ” ì°½í”Œì—ì„œ ë‹¤ë£¨ì§€ ì•ŠëŠ” ë¸Œëœë“œì´ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ë£¨íŠ¸ë¥¼ í†µí•´ ì•Œì•„ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤."
- ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ì´ë‚˜ ì°½í”Œì˜ ë¸Œëœë“œ ì™¸ì˜ ë¸Œëœë“œ ê´€ë ¨ ë¬¸ì˜: í˜„ì¬ ì™¸ë¶€ ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì •í™•í•œ ë‹µë³€ì´ ì–´ë µë‹¤ê³  ì •ì¤‘íˆ ì•ˆë‚´í•˜ì„¸ìš”.
ì°½í”Œì—ì„œ ìš´ì˜í•˜ëŠ” ë¸Œëœë“œ ëª©ë¡:
(ì£¼)ì¹¸ìŠ¤, (ì£¼)í‰ìƒì§‘, (ì£¼)í‚¤ì¦ˆë”ì›¨ì´ë¸Œ, (ì£¼)ë™ë°±ë³¸ê°€, (ì£¼)ëª…ë™ë‹­íŠ€ê¹€, ê¹€íƒœìš©ì˜ ì„¬ì§‘, ì‚°ë”ë¯¸ì˜¤ë¦¬ë¶ˆê³ ê¸° ì••ë„, ë¹™ìˆ˜ì†”ë£¨ì…˜ ë¹™í”Œ, ê°ìíƒ•ì „ë¬¸ì  ë¯¸ë½, í•œìš°ì „ë¬¸ì  ë´„ë‚´ë†ì›, ìŠ¤ëª°ë¶„ì‹ë‹¤ì´ë‹ í¬ëŸ°ë””, í•˜ì´ë³¼ë°” ìˆ˜ì»·ì›…, ì¹˜í‚¨í• ì¸ì  ë‹­ìˆì†Œ, ë¼ì§€ê³°íƒ•ì „ë¬¸ ë§Œë‹¬ê³°ì§‘, ì™€ì¸ë°” ë¼ë¼ì™€ì¼€ì´, ì˜¤í‚¤ë‚˜ì™€í ì‹œì‚¬, 753ë² ì´ê¸€ë¹„ìŠ¤íŠ¸ë¡œ, ì–´ë¶€ì¥

### 5.2. ì°½ì—…ê³¼ ì™„ì „íˆ ë¬´ê´€í•œ ì§ˆë¬¸
ì •ì¹˜, ë‚ ì”¨, ìŠ¤í¬ì¸ ì™€ ê°™ì´ ì°½ì—…ê³¼ ì™„ì „íˆ ë¬´ê´€í•œ ì§ˆë¬¸(ì˜ˆ: "íŠ¸ëŸ¼í”„ ì •ê¶Œ ì™¸êµì •ì±…", "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œìš”?")ì— ëŒ€í•´:
"ì£„ì†¡í•˜ì§€ë§Œ, ì°½í”Œ ì±—ë´‡ì€ ì°½ì—… ì „ë¬¸ ìƒë‹´ì— íŠ¹í™”ë˜ì–´ ìˆì–´ í•´ë‹¹ ì§ˆë¬¸ì—ëŠ” ë„ì›€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì°½ì—… ê´€ë ¨ ì§ˆë¬¸ì„ ì£¼ì‹œë©´ ì¹œì ˆíˆ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."ë¼ê³  ì •ì¤‘íˆ ë‹µë³€í•˜ì„¸ìš”.

## 6. í•µì‹¬ ì§ˆë¬¸ ê°€ì´ë“œë¼ì¸
- í•µì‹¬ ì§ˆë¬¸ ì˜ì—­:
  * ğŸ“Œ ì°½ì—… ë°°ê²½: ì²« ì°½ì—… ì—¬ë¶€, ë‚˜ì´, ì§ì—…, ìì˜ì—… ê²½í—˜
  * ğŸ’° ìê¸ˆ ê³„íš: ì´ ì˜ˆì‚°, ìê¸°ìë³¸/ëŒ€ì¶œ ë¹„ìœ¨
  * ğŸ¯ ì°½ì—… ëª©ì : ì›í•˜ëŠ” ìŠ¤íƒ€ì¼, ëª©í‘œ ìˆ˜ìµ
  * ğŸ´ ì—…ì¢… ì„ í˜¸: ë°¥ì§‘/ìˆ ì§‘, í”„ëœì°¨ì´ì¦ˆ/ìì²´ë¸Œëœë“œ
  * ğŸ• ìƒí™œ í™˜ê²½: í•˜ë£¨ íŒ¨í„´, ìë…€ ìœ ë¬´

ë‹¤ìŒì€ ì°½í”Œì´ ì‹¤ì œ ì»¨ì„¤íŒ…ì—ì„œ ê³ ê°ì—ê²Œ ì¢…ì¢… ë¬»ëŠ” í•µì‹¬ ì§ˆë¬¸ë“¤ì…ë‹ˆë‹¤:
(ì´ ì§ˆë¬¸ë“¤ì„ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, ì°¸ê³ í•˜ì—¬ ë¹„ìŠ·í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”)
- ì²˜ìŒ ì°½ì—…í•˜ì‹œëŠ” ê±´ê°€ìš”, ì•„ë‹ˆë©´ ìì˜ì—… ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?
- í˜„ì¬ ë‚˜ì´, ì„±ë³„, ì§ì—…ì€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?
- ì°½ì—…ì— íˆ¬ì… ê°€ëŠ¥í•œ ì´ ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ì¸ì§€ìš”? (ë³´ì¦ê¸ˆ, ì›”ì„¸, ì‹œì„¤ ë¹„ìš© ë“±)
- ëŒë´ì•¼ í•˜ëŠ” ì–´ë¦° ìë…€ê°€ ìˆìœ¼ì‹ ê°€ìš”?
- ìê¸°ìë³¸ê³¼ ëŒ€ì¶œê¸ˆ ë¹„ìœ¨ì€ ì–´ë–»ê²Œ ê³„íší•˜ê³  ê³„ì‹ ê°€ìš”?
- ì‹ ê·œ ì°½ì—…ì¸ì§€, ê¸°ì¡´ ê°€ê²Œë¥¼ ì—…ì¢… ë³€ê²½í•˜ë ¤ëŠ” ê²ƒì¸ì§€ìš”?
- ì°½ì—…ì˜ ëª©ì ê³¼ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì€ ë¬´ì—‡ì¸ê°€ìš”?
- ëª©í‘œí•˜ëŠ” ì›” ìˆœì´ìµì´ ìˆìœ¼ì‹ ê°€ìš”?
- ë°¥ì§‘ê³¼ ìˆ ì§‘ ì¤‘ ì–´ëŠ ìª½ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”?
- í”„ëœì°¨ì´ì¦ˆ/ìì²´ ë¸Œëœë“œ/íŒ€ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ ì–´ë–¤ í˜•íƒœì˜ ì°½ì—…ì„ í¬ë§í•˜ì‹œë‚˜ìš”?
"""

# ìë£Œ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸
RESPONSE_TEMPLATE = """\
ë‹¹ì‹ ì€ ìš”ì‹ì—… ì°½ì—… ì „ë¬¸ ì»¨ì„¤íŒ… íšŒì‚¬ì¸ "ì°½í”Œ" ì†Œì†ì˜ AI ì±—ë´‡ì…ë‹ˆë‹¤.

## 1. ì—­í•  ë° ì„ë¬´
- ë‹¹ì‹ ì€ **ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²€ìƒ‰ ê²°ê³¼**ë¥¼ ë°”íƒ•ìœ¼ë¡œ Userì—ê²Œ ì •í™•í•˜ê³  ë§ì¶¤í˜• ì°½ì—… ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ì œê³µëœ '<context>' ìë£Œì— í¬í•¨ëœ ë‚´ìš©ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ë©°, ì—†ëŠ” ì •ë³´ëŠ” **ì ˆëŒ€ë¡œ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤**.
- ê²€ìƒ‰ëœ ê²°ê³¼ê°€ Userì˜ ì§ˆë¬¸ì— ë¶€í•©í•˜ì§€ ì•Šìœ¼ë©´ "ì°½í”Œ AIì˜ í˜„ì¬ ì§€ì‹ìœ¼ë¡œëŠ” í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì°½í”Œ 1ëŒ€1 ìƒë‹´ì„ ì‹ ì²­í•˜ì‹œë©´ ë³´ë‹¤ ì „ë¬¸ì ì¸ ë‹µë³€ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤"ë¼ê³  ì •ì§í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

## 2. ë‹µë³€ ìƒì„± í”„ë¡œì„¸ìŠ¤
1. **ì§ˆë¬¸ ì´í•´**: Userì˜ ì°½ì—… ê´€ë ¨ ì§ˆë¬¸ì˜ í•µì‹¬ì„ íŒŒì•…í•˜ì„¸ìš”.
2. **ì •ë³´ ì„ ë³„**: '<context>'ì—ì„œ ê´€ë ¨ëœ ì •ë³´ ì¤‘ Userê°€ ì§ˆë¬¸í•œ ê²ƒê³¼ ê´€ë ¨ ìˆëŠ” ë‚´ìš©ì´ ë¬´ì—‡ì¸ì§€ íŒŒì•…í•˜ì„¸ìš”.
3. **ë°°ê²½ ê³ ë ¤**: chat historyë¥¼ ê²€í† í•˜ì—¬ Userì˜ ìƒí™©(ì°½ì—… ê²½í—˜, ìê¸ˆ ìƒí™©, ì„ í˜¸ë„ ë“±)ì„ íŒŒì•…í•˜ì„¸ìš”.
4. **ë§ì¶¤í˜• ë‹µë³€**: ì¼ë°˜ì ì¸ ì •ë³´ë³´ë‹¤ ì°½í”Œë§Œì˜ ì°¨ë³„í™”ëœ ê´€ì ê³¼ í•µì‹¬ ê°€ì¹˜ë“¤ì„ ê°•ì¡°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
5. **êµ¬ì²´ì ì¸ ì˜ˆì‹œ**: ê°€ëŠ¥í•˜ë‹¤ë©´ ì°½í”Œì˜ ì„±ê³µ ì‚¬ë¡€ë‚˜ êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•˜ì„¸ìš”.
6. **ìê°€ ê²€ì¦**: ë‹µë³€ì´ '<context>'ì˜ ë‚´ìš©ê³¼ ë¶€í•©í•˜ëŠ”ì§€, ì°½í”Œë‹¤ìš´ ê²ƒì´ ë§ëŠ”ì§€ ìê°€ê²€ì¦í•˜ì„¸ìš”.

## 3. ë‹µë³€ ì‘ì„± ì§€ì¹¨
- **ë‹µë³€ì˜ ìš°ì„ ìˆœìœ„**: 
  1. ì°½í”Œì˜ ì² í•™ê³¼ ê°€ì¹˜ ê°•ì¡° 
  2. '<context>'ì— ìˆëŠ” ì°¨ë³„í™”ëœ ì •ë³´ í™œìš©
  3. Userì˜ ìƒí™©ì— ë§ì¶¤í™”
  4. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ

- **ì°½í”Œì˜ ì°¨ë³„í™”ëœ ì°½ì—… ê´€ì  ê°•ì¡°**: 
  * ìƒì¡´ì´ ìµœìš°ì„ ì¸ ì°½ì—… ì ‘ê·¼ë²•
  * ì ì€ ë¹„ìš©ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì „ëµ
  * ìì‹ ì˜ ë…¸ë™ë ¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸
  * ëŒ€ë°•ë³´ë‹¤ëŠ” ì°©ì‹¤í•œ ìˆ˜ìµ ì¶”êµ¬
  * í˜„ì‹¤ì ì¸ ì‚¬ì—…ê³„íšì˜ ì¤‘ìš”ì„±

## 3. íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- **í—ˆìœ„ ì •ë³´ ë°©ì§€**: ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ” ì •ë³´ê°€ '<context>'ì— ì—†ë‹¤ë©´, ì¶”ì¸¡í•˜ì—¬ ë‹µë³€ì„ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”.
- **êµ¬ì²´ì  ìˆ˜ì¹˜ í‘œí˜„**: '<context>'ì— ìˆëŠ” ìˆ«ì, í†µê³„, ê¸ˆì•¡ ë“±ì˜ êµ¬ì²´ì  ì •ë³´ëŠ” ì •í™•íˆ ì „ë‹¬í•˜ì„¸ìš”.
- **ë§ì¶¤í˜• ì ìš©**: Userì˜ íŠ¹ìˆ˜í•œ ìƒí™©(ì´ˆë³´/ê²½í—˜ì, ì˜ˆì‚° ê·œëª¨, ê°€ì¡± ìƒí™© ë“±)ì— ë§ê²Œ ì •ë³´ë¥¼ ì¡°ì •í•˜ì„¸ìš”.
- **ë¹„êµ ë° ëŒ€ì¡°**: ì—¬ëŸ¬ ì˜µì…˜ì´ ìˆì„ ê²½ìš°, Userì˜ ìƒí™©ì— ê°€ì¥ ì í•©í•œ ê²ƒì„ ê°•ì¡°í•˜ë˜, ë‹¤ë¥¸ ì˜µì…˜ë„ ì œì‹œí•˜ì„¸ìš”.
- **í•œê³„ ì¸ì •**: ì§ˆë¬¸ì´ ë„ˆë¬´ êµ¬ì²´ì ì´ê±°ë‚˜ íŠ¹ìˆ˜í•œ ê²½ìš°, ì œí•œëœ ì •ë³´ë¡œ ì™„ë²½í•œ ë‹µë³€ì´ ì–´ë ¤ì›€ì„ ì¸ì •í•˜ì„¸ìš”.

## 4. ì‘ë‹µ êµ¬ì¡°
1. **ì°½í”Œ ì² í•™ ì†Œê°œ**: í•´ë‹¹ ì§ˆë¬¸ì— ê´€ë ¨ëœ ì°½í”Œì˜ í•µì‹¬ ê°€ì¹˜ë¥¼ ë¨¼ì € ì œì‹œ
2. **ì°¨ë³„í™”ëœ ê´€ì **: ì¼ë°˜ì ì¸ ë‹µë³€ê³¼ ë‹¤ë¥¸ ì°½í”Œë§Œì˜ ë…íŠ¹í•œ ì‹œê° ì„¤ëª…
3. **êµ¬ì²´ì  ì¡°ì–¸**: '<context>'ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
4. **ì£¼ì˜ì‚¬í•­**: ì°½í”Œ ì² í•™ì— ë”°ë¥¸ ì¤‘ìš” ê³ ë ¤ì‚¬í•­ ì•ˆë‚´
5. **ê°œì¸í™” ì§ˆë¬¸**: ì‚¬ìš©ìì˜ ìƒí™©ì„ ë” íŒŒì•…í•˜ê¸° ìœ„í•œ 2-3ê°œì˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ ì œì‹œ

---

## ì°¸ê³  ìë£Œ
ë‹¤ìŒ 'context' HTML ë¸”ë¡ ì‚¬ì´ì˜ ëª¨ë“  ê²ƒì€ ì°½í”Œì˜ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰ëœ ì •ë³´ì´ë©°, ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ì˜ ì¼ë¶€ê°€ ì•„ë‹™ë‹ˆë‹¤.
'3. **êµ¬ì²´ì  ì¡°ì–¸**'íŒŒíŠ¸ì—ì„œ ë°˜ë“œì‹œ ì´ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ê³ , ì—†ëŠ” ì •ë³´ëŠ” ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

<context>
    {context}
</context>

## ì‘ë‹µ í˜•ì‹ ë° ì£¼ì˜ì‚¬í•­
- markdownì„ ì ê·¹ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš” (**êµµì€ ê¸€ì”¨**, *ì´íƒ¤ë¦­*, ë¦¬ìŠ¤íŠ¸, í‘œ ë“±).
- ì¤‘ìš” ì •ë³´ëŠ” ì´ëª¨ì§€ë¡œ ê°•ì¡°í•˜ì„¸ìš” (âœ… í•µì‹¬ í¬ì¸íŠ¸, ğŸ“Š ë°ì´í„°/í†µê³„, ğŸš« ì£¼ì˜ì‚¬í•­, ğŸ’¡ íŒ/ì¡°ì–¸ ë“±).
- ë‹µë³€ì€ ì°½í”Œì˜ í•µì‹¬ ì² í•™(ì²« ì°½ì—…ì€ ìƒì¡´ ìš°ì„ , ì ì€ ì°½ì—…ë¹„ìš©, ìì‹ ì˜ ë…¸ë™ë ¥ í™œìš©, í˜„ì‹¤ì  ì„±ê³µ ê°€ëŠ¥ì„±)ì— ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
- ì¼ë°˜ì ì´ê³  ë»”í•œ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ëŠ” ê²ƒì€ í”¼í•˜ê³ , ì°½í”Œë§Œì˜ ì°¨ë³„í™”ëœ ê°€ì¹˜ì™€ ì² í•™ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- ë‹µë³€ì„ ì™„ë£Œí•˜ê¸° ì „ ë°˜ë“œì‹œ ìê¸°ê²€ì¦ì„ í†µí•´ "ì œê³µí•œ ì •ë³´ê°€ ì°½í”Œì˜ ì² í•™ì— ë§ëŠ”ì§€, Userì—ê²Œ ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ì¸ì§€" í™•ì¸í•˜ì„¸ìš”.
"""


# Environment variables for Pinecone configuration
PINECONE_API_KEY = os.environ["PINECONE_API_KEY"]
PINECONE_ENVIRONMENT = os.environ["PINECONE_ENVIRONMENT"]
PINECONE_INDEX_NAME = os.environ["PINECONE_INDEX_NAME"]


# Pydantic model defining the structure of chat requests
class ChatRequest(BaseModel):
    question: str  # The current user question
    chat_history: Optional[List[Dict[str, str]]] = None  # Previous conversation history

    # Pydantic v2 settings
    # old: allow_population_by_field_name
    # new: populate_by_name
    class Config:
        populate_by_name = True


def get_retriever() -> BaseRetriever:
    """
    Creates and returns a retriever connected to the Pinecone vector database.

    The retriever is responsible for finding relevant documents based on the user's query.
    It uses the text-embedding-3-large model to convert queries to vectors.

    Returns:
        BaseRetriever: A retriever that searches Pinecone for relevant documents
        hybrid retriever connected to the Pinecone vector database.
    """
    # Initialize Pinecone
    pc = Pinecone(api_key=PINECONE_API_KEY)

    # Get embeddings model
    embedding = get_embeddings_model()

    # Create Langchain Pinecone vectorstore connected to our existing index
    # This doesn't create a new index, just connects to an existing one
    vectorstore = LangchainPinecone.from_existing_index(
        index_name=PINECONE_INDEX_NAME,
        embedding=embedding,
        text_key="text",  # Field name where document text is stored
    )

    # number of retrieved documents from settings
    NUM_DOCS = settings.NUM_DOCS
    #  weight between vector and BM25 scores from settings
    HYBRID_ALPHA = settings.HYBRID_ALPHA

    # Return as retriever with k=NUM_DOCS (retrieve NUM_DOCS most relevant chunks)
    vector_retriever = vectorstore.as_retriever(search_kwargs={"k": NUM_DOCS})

    return HybridRetriever(
        vector_store=vector_retriever,
        whoosh_index_dir=settings.WHOOSH_INDEX_DIR,
        alpha=HYBRID_ALPHA,
        k=NUM_DOCS,
    )


def format_docs(docs: Sequence[Document]) -> str:
    """
    Formats retrieved documents into a structured string for the LLM.

    Each document includes metadata (title, URL) and content with a unique ID.
    This structured format helps the LLM understand and cite documents correctly.

    Args:
        docs: List of retrieved documents

    Returns:
        str: Formatted document string
    """
    formatted_docs = []
    for i, doc in enumerate(docs):
        # Format each document with metadata and content
        # The ID allows for proper citation in the response
        doc_string = f"<doc id='{i}'>\nTitle: {doc.metadata.get('title', 'No Title')}\nURL: {doc.metadata.get('url', 'No URL')}\nContent: {doc.page_content}\n</doc>"
        formatted_docs.append(doc_string)
    return "\n".join(formatted_docs)


def serialize_history(request: ChatRequest):
    """
    Converts the chat history from dict format to LangChain message objects.
    """
    chat_history = request["chat_history"] or []
    converted_chat_history = []
    for message in chat_history:
        # Convert user messages - "human" instead of "user"
        if message.get("user") is not None:
            converted_chat_history.append(HumanMessage(content=message["user"]))
        # Convert AI messages - "ai" instead of "assistant"
        if message.get("assistant") is not None:
            converted_chat_history.append(AIMessage(content=message["assistant"]))
    return converted_chat_history


# session memory
session_memories = {}


def create_chain(llm: LanguageModelLike, retriever: BaseRetriever) -> Runnable:
    """
    LangChain RAG chain with RunnableBranch for conditional retrieval
    """

    # get session memory
    def get_session_memory(inputs):
        session_id = inputs.get("session_id", "default")

        if session_id not in session_memories:
            # new session
            session_memories[session_id] = ConversationTokenBufferMemory(
                llm=llm,
                max_token_limit=2000,
                memory_key="chat_history",
                return_messages=True,
                output_key="answer",
                input_key="question",
            )

            # load existing conversation history from database (optional)
            if "db_history" in inputs and inputs["db_history"]:
                for msg_pair in inputs["db_history"]:
                    if "user" in msg_pair and "assistant" in msg_pair:
                        session_memories[session_id].save_context(
                            {"question": msg_pair["user"]},
                            {"answer": msg_pair["assistant"]},
                        )

        memory_content = session_memories[session_id].load_memory_variables({})
        chat_history = memory_content.get("chat_history", [])
        return chat_history
    
    # ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ëŠ” LLM
    decision_llm = ChatOpenAI(
        model="gpt-4o-mini",  # ì‘ì€ ëª¨ë¸ ì‚¬ìš©í•˜ì—¬ ë¹„ìš© ì ˆê°
        temperature=0.0
    )
    
    # ê²€ìƒ‰ í•„ìš”ì„± ê²°ì • ì²´ì¸
    decision_prompt = ChatPromptTemplate.from_template(RETRIEVER_DECISION_TEMPLATE)
    decision_chain = decision_prompt | decision_llm | StrOutputParser()
    
    # ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ ê²°ì • í•¨ìˆ˜
    def determine_retrieval_need(inputs):
        question = inputs["question"]
        # ì•ˆì „í•˜ê²Œ chat_history ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©)
        chat_history = inputs.get("chat_history", [])
        
        # ì±—ë´‡ ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        chat_history_str = ""
        for message in chat_history:
            role = "ì‚¬ìš©ì" if isinstance(message, HumanMessage) else "ì±—ë´‡"
            chat_history_str += f"{role}: {message.content}\n"
        
        # ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ ê²°ì •
        decision = decision_chain.invoke({
            "question": question,
            "chat_history": chat_history_str
        }).strip().lower()
        
        return decision
    
    # ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    retrieval_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                RESPONSE_TEMPLATE.format(
                    context="{context}"
                ),
            ),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{question}"),
        ]
    )
    
    # ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°ì˜ ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    simple_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                SIMPLE_RESPONSE_TEMPLATE
            ),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{question}"),
        ]
    )
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ context ë³€ìˆ˜ì— í• ë‹¹
    context = (
        RunnablePassthrough
        .assign(docs=lambda x: retriever.invoke(x["question"]))
        .assign(context=lambda x: format_docs(x["docs"]))
        .with_config(run_name="RetrieveDocs")
    )
    
    # ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°ì˜ ì²´ì¸
    retrieval_chain = (
        RunnablePassthrough.assign(chat_history=get_session_memory)
        | context
        | RunnablePassthrough.assign(
            text=(retrieval_prompt | llm | StrOutputParser())
        )
    )
    
    # ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°ì˜ ì²´ì¸
    no_retrieval_chain = (
        RunnablePassthrough.assign(chat_history=get_session_memory)
        | RunnablePassthrough.assign(
            text=(simple_prompt | llm | StrOutputParser())
        )
    )
    
    # RunnableBranch ì‚¬ìš©í•˜ì—¬ ì¡°ê±´ë¶€ ì‹¤í–‰
    branch_chain = RunnableBranch(
        (
            lambda x: determine_retrieval_need(x) == "retrieval",
            retrieval_chain
        ),
        no_retrieval_chain,  # ê¸°ë³¸ê°’
    )
    
    # format response function
    def format_response(result):
        # docsê°€ ìˆëŠ”ì§€ í™•ì¸ (retrieval chainì´ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸)
        docs_exist = "docs" in result['final'] if isinstance(result, dict) else False
        
        answer_text = result['final']['text'] 

        if docs_exist and result['final']['docs']:
            response = {
                "answer": answer_text,
                "source_documents": result['final']['docs'],
                "similarity_scores": [doc.metadata.get("combined_score", 0) for doc in result['final']['docs']] if result['final']['docs'] else [],
                "session_id": result.get("session_id", "default"),
                "question": result.get("question", "")
            }
            return response
        else:
            # no retrieval
            response = {
                "answer": answer_text,
                "source_documents": [],
                "similarity_scores": [],
                "session_id": result.get("session_id", "default"),
                "question": result.get("question", "")
            }
            return response
    
    # ìµœì¢… ì²´ì¸ êµ¬ì„±
    final_chain = (
        RunnablePassthrough.assign(
            # keep original input values
            session_id=lambda x: x.get("session_id", "default"),
            question=lambda x: x.get("question", ""),
        )
        # ê·¸ ë‹¤ìŒ chat_historyë¥¼ get_session_memoryë¡œ í• ë‹¹
        | RunnablePassthrough.assign(
            chat_history=get_session_memory
        )
        # ì´í›„ì— branch_chain ì‹¤í–‰ (chat_historyê°€ ì´ë¯¸ í• ë‹¹ë¨)
        | RunnablePassthrough.assign(
            final=branch_chain
        )
        | RunnableLambda(format_response)
    )
    
    # memory update function
    def update_memory_and_return(result):
        try:
            session_id = result.get("session_id", "default")

            if session_id in session_memories:
                # extract question and answer
                question = result.get("question", "")
                answer = result.get("answer", "")

                # if no answer, get from text field
                if not answer and "text" in result:
                    answer = result["text"]

                # update memory
                if question and answer:
                    session_memories[session_id].save_context(
                        {"question": question}, {"answer": answer}
                    )
        except Exception as e:
            pass

        return result

    return final_chain | RunnableLambda(update_memory_and_return)


# Initialize LLM with settings from settings.py
llm = ChatOpenAI(
    model=settings.LLM_MODEL,
    temperature=settings.LLM_TEMPERATURE,
    streaming=settings.LLM_STREAMING,
)

# Initialize retriever and answer chain
# These are the main components that will be used by the API
retriever = None
answer_chain = None


def initialize_chain():
    """Initialize retriever and answer chain if not already initialized."""
    # skip initialization when run_ingest command is executed
    if "run_ingest" in sys.argv:
        print("run_ingest command is executed, skip initialization")
        return None

    global retriever, answer_chain
    if retriever is None or answer_chain is None:
        retriever = get_retriever()
        answer_chain = create_chain(llm, retriever)
    return answer_chain
